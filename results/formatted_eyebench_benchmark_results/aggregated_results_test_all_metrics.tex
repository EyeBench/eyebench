
\begin{table}[ht]
\centering
\caption{Feature types used by each model, and aggregated model performance across all benchmark tasks and metrics. \textbf{Layout} stands for information about the position of the text or fixations on the screen. Eye movement features are divided into three levels of granularity: \textbf{Saccades/Fixations} (e.g., fixation duration), \textbf{Words} (e.g., total fixation duration on a given word), and \textbf{Trial} (e.g., average total fixation duration across all the words during the trial). Text features are divided into: \textbf{Linguistic} word properties (e.g., word frequency) and contextual word \textbf{Embeddings} (e.g., RoBERTa embeddings). \textbf{Average Normalized Score} is the mean of min-max normalized scores across all tasks and metrics (higher is better). \textbf{Mean Rank} is the mean ranking across all tasks and metrics (lower is better). Best performing model for each aggregation metric is shown in \textbf{bold}.}
\resizebox{\linewidth}{!}{%
\begin{tabular}{l|c|ccc|cc||cc}
\toprule
\textbf{Model} & \multicolumn{1}{c|}{\textbf{Layout}} & \multicolumn{3}{c|}{\textbf{Eye movement features}} & \multicolumn{2}{c||}{\textbf{Text features}}  & \multicolumn{2}{c}{\textbf{Aggregated performance}}\\
&  & \makecell{Saccade/\\Fixation Level} & \makecell{Word\\Level} & \makecell{Trial\\Level} & Linguistic & Embeddings & Avg. Normalized Score$\uparrow$ & Mean Rank$\downarrow$\\
\midrule
Majority Class / Chance & - & - & - & - & - & - & 0.367 & 10.10 \\
Reading Speed & - & - & - & \checkmark & - & - & 0.421 & 10.29 \\
Text-Only Roberta & - & - & - & - & - & \checkmark & 0.672 & 6.10 \\
\midrule
Logistic Regression~\cite{meziere2023using} & - & - & - & \checkmark & - & - & 0.571 & 7.67 \\
SVM~\cite{hollenstein2023zuco} & - & - & - & \checkmark & - & - & 0.521 & 7.38 \\
Random Forest~\cite{makowski2024detection} & - & \checkmark & - & \checkmark & \checkmark & - & \textbf{0.788} & 4.48 \\
\midrule
AhnRNN~\citep{ahn2020towards} & \checkmark & \checkmark & - & - & - & - & 0.360 & 9.48 \\
AhnCNN~\citep{ahn2020towards} & \checkmark & \checkmark & - & - & - & - & 0.531 & 6.95 \\
BEyeLSTM~\citep{reich_inferring_2022} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & - & 0.414 & 9.10 \\
PLM-AS~\citep{Yang2023PLMASPL} & - & \checkmark & - & - & - & \checkmark & 0.494 & 8.00 \\
PLM-AS-RM~\citep{haller2022eye} & - & \checkmark & \checkmark & - & - & \checkmark & 0.475 & 8.95 \\
RoBERTEye-W~\citep{Shubi2024Finegrained} & \checkmark & - & \checkmark & \checkmark & \checkmark & \checkmark & 0.757 & \textbf{4.43} \\
RoBERTEye-F~\citep{Shubi2024Finegrained} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & 0.654 & 6.81 \\
MAG-Eye~\citep{Shubi2024Finegrained} & \checkmark & - & \checkmark & \checkmark & \checkmark & \checkmark & 0.686 & 5.62 \\
PostFusion-Eye~\citep{Shubi2024Finegrained} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & 0.546 & 9.81 \\

\bottomrule
\end{tabular}%
}
\label{tab:features-per-model-results-test_all_metrics}
\end{table}
